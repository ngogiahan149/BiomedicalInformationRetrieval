from openFile import *
import nltk, re
from nltk.tokenize import sent_tokenize

def count_sentences_xml(rows):

    for i, (PMID, 
            JournalISSN,
            JournalTitle,
            ISOAbbreviation,
            ArticleTitle,
            Language,
            AbstractList,          
            AuthorList,
            KeywordList,
            PublicationTypeList,
            JournalCountry,
            ) in enumerate(rows, start = 1):
        sentences = (' '.join([item.text for item in AbstractList]))
        number_of_sentences = sent_tokenize(sentences)
    return len(number_of_sentences)

def preprocessing(text):
    # Removing Square Brackets and Extra Spaces
    text = re.sub(r'\[[0-9]*\]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    
    # Removing special characters and digits
    formatted_article_text = re.sub('[^a-zA-Z]', ' ', text)
    formatted_article_text = re.sub(r'\s+', ' ', text)